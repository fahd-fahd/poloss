#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import discord
from discord.ext import commands
import asyncio
import os
import io
import re
import wavelink
import speech_recognition as sr
import whisper
import azure.cognitiveservices.speech as speechsdk
from typing import Optional, List, Dict, Tuple
import tempfile
import numpy as np
import logging
import yt_dlp
import json
import time
from pydub import AudioSegment
import threading

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("voice_assistant.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("VoiceAssistant")

# Constants and configuration
DISCORD_BOT_TOKEN = os.getenv("DISCORD_BOT_TOKEN", "")
AZURE_TTS_KEY = os.getenv("AZURE_TTS_KEY", "")
AZURE_REGION = os.getenv("AZURE_REGION", "eastus")
WHISPER_MODEL = os.getenv("WHISPER_MODEL", "small")  # small, medium, large models
USE_GOOGLE_STT = os.getenv("USE_GOOGLE_STT", "False").lower() == "true"

class VoiceAssistant(commands.Cog):
    """Discord Voice Assistant with voice recognition and TTS"""
    
    def __init__(self, bot):
        self.bot = bot
        self.voice_connections = {}  # guild_id -> VoiceConnection
        self.whisper_model = None
        self.recognizer = sr.Recognizer()
        self.is_listening = {}  # guild_id -> bool
        self.audio_queues = {}  # guild_id -> Queue
        self.should_stop = {}  # guild_id -> bool
        self.speakers = {
            "ar-SA": {
                "male": ["ar-SA-HamedNeural"],  # Arabic Saudi male voice
                "female": ["ar-SA-ZariyahNeural"]  # Arabic Saudi female voice
            },
            "en-US": {
                "male": ["en-US-GuyNeural"],
                "female": ["en-US-JennyNeural"]
            }
        }
        self.default_voice = "ar-SA-HamedNeural"  # Default voice - Arabic Saudi male
        self.command_patterns = {
            "play": [
                r"Ø´ØºÙ„ (.+)",
                r"ØªØ´ØºÙŠÙ„ (.+)",
                r"Ø§Ø¨ÙŠ Ø§Ø³Ù…Ø¹ (.+)",
                r"Ø§Ø¨ØºÙ‰ Ø§Ø³Ù…Ø¹ (.+)",
                r"Ø­Ø· Ù„ÙŠ (.+)",
                r"Ø­Ø· (.+)",
                r"Ø´ØºÙ„ÙŠ (.+)",
                r"play (.+)"
            ],
            "stop": [
                r"ÙˆÙ‚Ù",
                r"ØªÙˆÙ‚Ù",
                r"Ø£ÙˆÙ‚Ù",
                r"Ø§ÙŠÙ‚Ø§Ù",
                r"Ø¥ÙŠÙ‚Ø§Ù",
                r"stop"
            ],
            "next": [
                r"Ø§Ù„ØªØ§Ù„ÙŠ",
                r"Ø§Ù„ØªØ§Ù„ÙŠØ©",
                r"Ø§Ù„ÙŠ Ø¨Ø¹Ø¯Ù‡",
                r"Ø§Ù„ÙŠ Ø¨Ø¹Ø¯Ù‡Ø§",
                r"Ø§Ù„Ù„ÙŠ Ø¨Ø¹Ø¯Ù‡",
                r"Ø§Ù„Ù„ÙŠ Ø¨Ø¹Ø¯Ù‡Ø§",
                r"next",
                r"skip"
            ],
            "pause": [
                r"ÙˆÙ‚Ù Ù…Ø¤Ù‚Øª",
                r"ØªÙˆÙ‚Ù Ù…Ø¤Ù‚Øª",
                r"Ø¥ÙŠÙ‚Ø§Ù Ù…Ø¤Ù‚Øª",
                r"Ø§ÙŠÙ‚Ø§Ù Ù…Ø¤Ù‚Øª",
                r"pause"
            ],
            "resume": [
                r"ÙƒÙ…Ù„",
                r"Ø§Ø³ØªÙ…Ø±",
                r"Ø§Ø³ØªÙƒÙ…Ø§Ù„",
                r"ÙˆØ§ØµÙ„",
                r"resume"
            ],
            "volume": [
                r"ØµÙˆØª (\d+)",
                r"Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØµÙˆØª (\d+)",
                r"Ø­Ø¬Ù… Ø§Ù„ØµÙˆØª (\d+)",
                r"Ø§Ø±ÙØ¹ Ø§Ù„ØµÙˆØª",
                r"Ù†Ø²Ù„ Ø§Ù„ØµÙˆØª",
                r"volume (\d+)",
                r"Ø¬ÙŠØ¨ Ø§Ù„ØµÙˆØª Ø¹Ù„Ù‰ (\d+)"
            ]
        }
        self.initialize_whisper()
    
    def initialize_whisper(self):
        """Initialize the Whisper model for speech recognition"""
        logger.info(f"Initializing Whisper model: {WHISPER_MODEL}")
        try:
            self.whisper_model = whisper.load_model(WHISPER_MODEL)
            logger.info(f"Whisper model loaded successfully: {WHISPER_MODEL}")
        except Exception as e:
            logger.error(f"Failed to load Whisper model: {str(e)}")
            logger.warning("Voice recognition with Whisper will not be available")
    
    async def azure_tts(self, text, filename=None, voice_name=None):
        """Generate speech from text using Azure Text-to-Speech"""
        if not AZURE_TTS_KEY or AZURE_TTS_KEY == "":
            logger.error("Azure TTS key is not configured")
            return None
        
        try:
            # Configure speech configuration
            speech_config = speechsdk.SpeechConfig(subscription=AZURE_TTS_KEY, region=AZURE_REGION)
            
            # Use default voice if none specified
            voice_name = voice_name or self.default_voice
            speech_config.speech_synthesis_voice_name = voice_name
            
            # Create temp file if filename not provided
            if not filename:
                fd, filename = tempfile.mkstemp(suffix='.wav')
                os.close(fd)
            
            # Configure audio output to a file
            audio_config = speechsdk.audio.AudioOutputConfig(filename=filename)
            
            # Create speech synthesizer
            synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)
            
            # Synthesize text to speech
            result = synthesizer.speak_text_async(text).get()
            
            # Check result
            if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
                logger.info(f"Speech synthesis completed: {filename}")
                return filename
            else:
                logger.error(f"Speech synthesis failed: {result.reason}")
                if result.cancellation_details:
                    logger.error(f"Speech synthesis canceled: {result.cancellation_details.reason}")
                    if result.cancellation_details.reason == speechsdk.CancellationReason.Error:
                        logger.error(f"Error details: {result.cancellation_details.error_details}")
                return None
                
        except Exception as e:
            logger.error(f"Azure TTS error: {str(e)}")
            return None
    
    async def play_audio_file(self, voice_client, file_path):
        """Play an audio file in the voice channel"""
        if not voice_client or not voice_client.is_connected():
            logger.error("Cannot play audio: Voice client not connected")
            return False
        
        try:
            # Create the audio source from the file
            source = discord.FFmpegPCMAudio(file_path)
            
            # Play the audio in the voice channel
            if voice_client.is_playing():
                voice_client.stop()
            
            voice_client.play(source)
            
            # Wait for the audio to finish
            while voice_client.is_playing():
                await asyncio.sleep(0.5)
            
            return True
            
        except Exception as e:
            logger.error(f"Error playing audio file: {str(e)}")
            return False
    
    async def transcribe_with_whisper(self, audio_data, language="ar"):
        """Transcribe audio data using Whisper"""
        if not self.whisper_model:
            logger.error("Whisper model not initialized")
            return None
        
        try:
            # Convert audio data to a format compatible with Whisper
            # This assumes audio_data is in PCM format from Discord
            # We need to write it to a temporary file and read it back
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                temp_filename = temp_file.name
            
            # Write audio data to WAV file
            with open(temp_filename, 'wb') as f:
                f.write(audio_data)
            
            # Use Whisper to transcribe the audio
            result = self.whisper_model.transcribe(temp_filename, language=language)
            
            # Clean up the temporary file
            try:
                os.unlink(temp_filename)
            except Exception as e:
                logger.warning(f"Failed to delete temporary file: {str(e)}")
            
            return result["text"].strip()
            
        except Exception as e:
            logger.error(f"Whisper transcription error: {str(e)}")
            return None
    
    async def transcribe_with_google(self, audio_data):
        """Transcribe audio data using Google Speech Recognition"""
        if not self.recognizer:
            return None
        
        try:
            # Convert audio data to a format compatible with speech_recognition
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                temp_filename = temp_file.name
            
            # Write audio data to WAV file
            with open(temp_filename, 'wb') as f:
                f.write(audio_data)
            
            # Read audio from the file
            with sr.AudioFile(temp_filename) as source:
                audio = self.recognizer.record(source)
            
            # Transcribe using Google
            text = self.recognizer.recognize_google(audio, language="ar-AR")
            
            # Clean up the temporary file
            try:
                os.unlink(temp_filename)
            except Exception as e:
                logger.warning(f"Failed to delete temporary file: {str(e)}")
            
            return text.strip()
            
        except sr.UnknownValueError:
            logger.warning("Google Speech Recognition could not understand audio")
            return None
            
        except sr.RequestError as e:
            logger.error(f"Google Speech Recognition service error: {str(e)}")
            return None
            
        except Exception as e:
            logger.error(f"Google transcription error: {str(e)}")
            return None
    
    def parse_command(self, text):
        """Parse voice command from transcribed text"""
        if not text:
            return None, None
        
        # Check for each command pattern
        for command, patterns in self.command_patterns.items():
            for pattern in patterns:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    # For commands that may have parameters
                    if len(match.groups()) > 0:
                        return command, match.group(1)
                    return command, None
        
        # No command found
        return None, None
    
    async def process_command(self, ctx, command, param):
        """Process the parsed command"""
        guild_id = ctx.guild.id
        voice_client = ctx.voice_client
        
        if not voice_client:
            return "Ù„Ø³Øª Ù…ØªØµÙ„ Ø¨Ù‚Ù†Ø§Ø© ØµÙˆØªÙŠØ©"
        
        if command == "play":
            if not param:
                return "Ù„Ù… Ø£ÙÙ‡Ù… Ù…Ø§Ø°Ø§ ØªØ±ÙŠØ¯ Ø£Ù† Ø£Ø´ØºÙ„"
            
            # Generate response first
            response = f"Ø£ÙƒÙŠØ¯ØŒ Ø±Ø§Ø­ Ø£Ø´ØºÙ„ Ù„Ùƒ {param}"
            
            # Respond with TTS
            await self.respond_with_tts(ctx, response)
            
            # Play the requested song
            await self.play_song(ctx, param)
            return None
            
        elif command == "stop":
            # Stop the player
            player = self.bot.wavelink.get_player(guild_id)
            if player:
                await player.disconnect()
                return "ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ´ØºÙŠÙ„"
            return "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ø­ØªÙˆÙ‰ Ù‚ÙŠØ¯ Ø§Ù„ØªØ´ØºÙŠÙ„"
            
        elif command == "next":
            # Skip to next song
            player = self.bot.wavelink.get_player(guild_id)
            if player and player.is_playing():
                await player.stop()
                return "Ø¬Ø§Ø±ÙŠ ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØªØ§Ù„ÙŠ"
            return "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ø­ØªÙˆÙ‰ Ù‚ÙŠØ¯ Ø§Ù„ØªØ´ØºÙŠÙ„"
            
        elif command == "pause":
            # Pause playback
            player = self.bot.wavelink.get_player(guild_id)
            if player and player.is_playing():
                await player.pause()
                return "ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ´ØºÙŠÙ„ Ù…Ø¤Ù‚ØªÙ‹Ø§"
            return "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ø­ØªÙˆÙ‰ Ù‚ÙŠØ¯ Ø§Ù„ØªØ´ØºÙŠÙ„"
            
        elif command == "resume":
            # Resume playback
            player = self.bot.wavelink.get_player(guild_id)
            if player and player.is_paused():
                await player.resume()
                return "ØªÙ… Ø§Ø³ØªØ¦Ù†Ø§Ù Ø§Ù„ØªØ´ØºÙŠÙ„"
            return "Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù„ÙŠØ³ Ù…ØªÙˆÙ‚ÙÙ‹Ø§ Ù…Ø¤Ù‚ØªÙ‹Ø§"
            
        elif command == "volume":
            # Set volume
            player = self.bot.wavelink.get_player(guild_id)
            if player:
                try:
                    volume = int(param) if param else 70
                    volume = max(0, min(100, volume))
                    await player.set_volume(volume)
                    return f"ØªÙ… Ø¶Ø¨Ø· Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØµÙˆØª Ø¹Ù„Ù‰ {volume}%"
                except ValueError:
                    # Handle directional volume changes
                    if param in ["Ø§Ø±ÙØ¹", "Ø²ÙˆØ¯", "Ø²ÙŠØ¯"]:
                        current_volume = player.volume
                        new_volume = min(100, current_volume + 20)
                        await player.set_volume(new_volume)
                        return f"ØªÙ… Ø±ÙØ¹ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ {new_volume}%"
                    elif param in ["Ù†Ø²Ù„", "Ø®ÙØ¶", "Ù‚Ù„Ù„"]:
                        current_volume = player.volume
                        new_volume = max(0, current_volume - 20)
                        await player.set_volume(new_volume)
                        return f"ØªÙ… Ø®ÙØ¶ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ {new_volume}%"
                    return "Ù„Ù… Ø£ÙÙ‡Ù… Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØµÙˆØª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨"
            return "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ø´ØºÙ„ ØµÙˆØª Ù†Ø´Ø·"
        
        # Unknown command
        return "Ù„Ù… Ø£ÙÙ‡Ù… Ø§Ù„Ø£Ù…Ø±"
    
    async def respond_with_tts(self, ctx, response_text):
        """Respond with text-to-speech in the voice channel"""
        if not ctx.voice_client or not ctx.voice_client.is_connected():
            logger.error("Cannot respond: Not connected to voice channel")
            return
        
        try:
            # Create temporary file for TTS audio
            fd, temp_filename = tempfile.mkstemp(suffix='.wav')
            os.close(fd)
            
            # Generate TTS audio
            tts_file = await self.azure_tts(response_text, temp_filename)
            
            if not tts_file:
                logger.error("TTS generation failed")
                return
            
            # Play the TTS response
            await self.play_audio_file(ctx.voice_client, tts_file)
            
            # Clean up the temporary file
            try:
                os.unlink(temp_filename)
            except Exception as e:
                logger.warning(f"Failed to delete temporary file: {str(e)}")
                
        except Exception as e:
            logger.error(f"Error in voice response: {str(e)}")
    
    async def play_song(self, ctx, search_query):
        """Play a song based on the search query"""
        # Make sure we're connected to a voice channel
        if not ctx.voice_client or not ctx.voice_client.is_connected():
            logger.error("Cannot play song: Not connected to voice channel")
            return
        
        try:
            # Get the music player cog
            music_cog = self.bot.get_cog("MusicPlayer")
            if not music_cog:
                logger.error("MusicPlayer cog not found")
                await ctx.send("âš ï¸ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø´ØºÙ„ Ø§Ù„Ù…ÙˆØ³ÙŠÙ‚Ù‰")
                return
            
            # Use the existing play command in the music cog
            # This will handle searching on YouTube, loading, and playing the track
            await music_cog.play(ctx, query=search_query)
            
        except Exception as e:
            logger.error(f"Error playing song: {str(e)}")
            await ctx.send(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø£ØºÙ†ÙŠØ©: {str(e)}")
    
    async def start_listening(self, ctx):
        """Start listening to voice input in a voice channel"""
        if not ctx.author.voice:
            await ctx.send("âŒ ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† ÙÙŠ Ù‚Ù†Ø§Ø© ØµÙˆØªÙŠØ© Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‡Ø°Ø§ Ø§Ù„Ø£Ù…Ø±")
            return False
        
        guild_id = ctx.guild.id
        
        # Check if already listening in this guild
        if guild_id in self.is_listening and self.is_listening[guild_id]:
            await ctx.send("ğŸ‘‚ Ø£Ù†Ø§ Ø¨Ø§Ù„ÙØ¹Ù„ Ø£Ø³ØªÙ…Ø¹ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù‚Ù†Ø§Ø© Ø§Ù„ØµÙˆØªÙŠØ©")
            return False
        
        # Join the voice channel
        voice_channel = ctx.author.voice.channel
        if ctx.voice_client:
            await ctx.voice_client.move_to(voice_channel)
            voice_client = ctx.voice_client
        else:
            try:
                voice_client = await voice_channel.connect()
            except discord.ClientException as e:
                await ctx.send(f"âŒ Ù„Ù… Ø£ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø§Ù†Ø¶Ù…Ø§Ù… Ø¥Ù„Ù‰ Ø§Ù„Ù‚Ù†Ø§Ø© Ø§Ù„ØµÙˆØªÙŠØ©: {str(e)}")
                return False
        
        # Signal that we're listening
        self.is_listening[guild_id] = True
        self.should_stop[guild_id] = False
        
        # Initialize audio queue
        if guild_id not in self.audio_queues:
            self.audio_queues[guild_id] = asyncio.Queue()
        
        # Respond with TTS
        await self.respond_with_tts(ctx, "Ù…Ø±Ø­Ø¨Ø§Ù‹ØŒ Ø£Ù†Ø§ Ø§Ù„Ø¢Ù† Ø£Ø³ØªÙ…Ø¹ Ø¥Ù„Ù‰ Ø·Ù„Ø¨Ø§ØªÙƒ Ø§Ù„ØµÙˆØªÙŠØ©. ÙŠÙ…ÙƒÙ†Ùƒ Ø·Ù„Ø¨ ØªØ´ØºÙŠÙ„ Ø£ØºÙ†ÙŠØ© Ù…Ø«Ù„ 'Ø´ØºÙ„ Ø£ØºÙ†ÙŠØ© Ù†Ø§Ù†Ø³ÙŠ ÙŠØ§ Ø³Ù„Ø§Ù…'")
        
        # Start the listener
        listener_task = asyncio.create_task(self._listen_to_voice(ctx, voice_client))
        
        # Start the processor
        processor_task = asyncio.create_task(self._process_voice_audio(ctx))
        
        return True
    
    async def stop_listening(self, ctx):
        """Stop listening to voice input"""
        guild_id = ctx.guild.id
        
        if guild_id not in self.is_listening or not self.is_listening[guild_id]:
            await ctx.send("âŒ Ø£Ù†Ø§ Ù„Ø³Øª ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹ Ø­Ø§Ù„ÙŠÙ‹Ø§")
            return False
        
        # Signal to stop listening
        self.should_stop[guild_id] = True
        self.is_listening[guild_id] = False
        
        # Respond with TTS
        await self.respond_with_tts(ctx, "Ø­Ø³Ù†Ø§Ù‹ØŒ ØªÙˆÙ‚ÙØª Ø¹Ù† Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹. ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ¯Ø¹Ø§Ø¦ÙŠ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ù…Ø± Ø§Ø³ØªÙ…Ø¹")
        
        return True
    
    async def _listen_to_voice(self, ctx, voice_client):
        """Listen to voice in the voice channel and queue audio packets"""
        guild_id = ctx.guild.id
        
        # Make sure we're connected and listening
        if not voice_client or not voice_client.is_connected() or not self.is_listening.get(guild_id, False):
            logger.error("Voice client not connected or not listening")
            return
        
        logger.info(f"Starting voice listening in guild {guild_id}")
        
        # Set up a sink to record audio
        sink = discord.sinks.WaveSink()
        
        # Start recording
        voice_client.start_recording(
            sink,
            self._recording_finished,
            ctx
        )
        
        # Wait until stop is requested
        while not self.should_stop.get(guild_id, True):
            await asyncio.sleep(0.5)
        
        # Stop recording
        voice_client.stop_recording()
        logger.info(f"Stopped voice listening in guild {guild_id}")
    
    async def _process_voice_audio(self, ctx):
        """Process the voice audio from the queue"""
        guild_id = ctx.guild.id
        
        logger.info(f"Starting voice audio processor for guild {guild_id}")
        
        # Process audio while we're still listening
        while self.is_listening.get(guild_id, False):
            try:
                # Get audio data from the queue (with timeout)
                try:
                    audio_data = await asyncio.wait_for(
                        self.audio_queues[guild_id].get(),
                        timeout=1.0
                    )
                except asyncio.TimeoutError:
                    continue
                
                # Skip processing if we're no longer listening
                if not self.is_listening.get(guild_id, False):
                    break
                
                # Transcribe the audio
                if USE_GOOGLE_STT:
                    transcript = await self.transcribe_with_google(audio_data)
                else:
                    transcript = await self.transcribe_with_whisper(audio_data)
                
                if not transcript:
                    logger.debug("No transcript detected")
                    continue
                
                logger.info(f"Transcribed: {transcript}")
                
                # Parse and process command
                command, param = self.parse_command(transcript)
                
                if command:
                    logger.info(f"Detected command: {command}, param: {param}")
                    
                    # Process the command
                    response = await self.process_command(ctx, command, param)
                    
                    # Respond if needed
                    if response:
                        await self.respond_with_tts(ctx, response)
                
            except Exception as e:
                logger.error(f"Error processing voice audio: {str(e)}")
                await asyncio.sleep(1)
        
        logger.info(f"Stopped voice audio processor for guild {guild_id}")
    
    def _recording_finished(self, sink, ctx):
        """Callback when a recording is finished"""
        # Check if we're still listening
        guild_id = ctx.guild.id
        if not self.is_listening.get(guild_id, False):
            return
        
        # Retrieve audio data for the bot's user
        for user_id, audio in sink.audio_data.items():
            # Skip the bot's own audio
            if user_id == self.bot.user.id:
                continue
            
            # Queue the audio data for processing
            if guild_id in self.audio_queues:
                asyncio.run_coroutine_threadsafe(
                    self.audio_queues[guild_id].put(audio.file.getvalue()),
                    self.bot.loop
                )
    
    @commands.command(
        name="Ø§Ø³ØªÙ…Ø¹",
        aliases=["listen", "voice", "ØµÙˆØª"],
        description="Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹ Ù„Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØµÙˆØªÙŠØ©"
    )
    async def listen_command(self, ctx):
        """Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹ Ù„Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØµÙˆØªÙŠØ© ÙÙŠ Ù‚Ù†Ø§Ø© ØµÙˆØªÙŠØ©"""
        success = await self.start_listening(ctx)
        if success:
            embed = discord.Embed(
                title="ğŸ§ ÙˆØ¶Ø¹ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹",
                description="Ø¨Ø¯Ø£Øª Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹ Ù„Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØµÙˆØªÙŠØ©. ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¢Ù† Ø§Ù„ØªØ­Ø¯Ø« Ø¨Ø£ÙˆØ§Ù…Ø± Ù…Ø«Ù„:\n\n" +
                            "- Ø´ØºÙ„ Ø£ØºÙ†ÙŠØ© Ù†Ø§Ù†Ø³ÙŠ Ø¹Ø¬Ø±Ù… ÙŠØ§ Ø³Ù„Ø§Ù…\n" +
                            "- ÙˆÙ‚Ù\n" +
                            "- Ø§Ù„ØªØ§Ù„ÙŠ\n" +
                            "- ØµÙˆØª 50",
                color=discord.Color.green()
            )
            embed.set_footer(text="Ø§Ø³ØªØ®Ø¯Ù… Ø£Ù…Ø± 'ØªÙˆÙ‚Ù' Ù„Ù„Ø®Ø±ÙˆØ¬ Ù…Ù† ÙˆØ¶Ø¹ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹")
            await ctx.send(embed=embed)
    
    @commands.command(
        name="ØªÙˆÙ‚Ù",
        aliases=["stop_listen", "Ù‚Ù"],
        description="Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹ Ù„Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØµÙˆØªÙŠØ©"
    )
    async def stop_listen_command(self, ctx):
        """Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹ Ù„Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØµÙˆØªÙŠØ©"""
        success = await self.stop_listening(ctx)
        if success:
            embed = discord.Embed(
                title="ğŸ”‡ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹",
                description="ØªÙˆÙ‚ÙØª Ø¹Ù† Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹ Ù„Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØµÙˆØªÙŠØ©.",
                color=discord.Color.red()
            )
            await ctx.send(embed=embed)

async def setup(bot):
    """Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙ†Ù"""
    await bot.add_cog(VoiceAssistant(bot)) 